# docker compose is a tool for defining and running multi-container Docker applications
# docker compose allows to treat a group of containers as single entity, i.e. "run an app" (run an orchestrated cluster of containers) instead of "run a container"
# pip install docker-compose

# to destroy the cluster and data volumes, add -v
# docker-compose down -v

version: '3.7'  # version of docker-compose, not Python
services:
  web:
    restart: always
    build: . 
    command: python /Finance_Django_Project/manage.py runserver 0.0.0.0:8000
    volumes: 
      - .:/Finance_Django_Project
    ports:
      - 8000:8000
    env_file: .env
    depends_on:
      - postgres
      - redis
    links:
      - postgres:postgres
      - redis:redis
    networks:
      - djangonetwork

  postgres:
    image: postgres:11
    restart: always
    env_file: .env
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
    - djangonetwork

  pgadmin:
    image: dpage/pgadmin4:4.18
    env_file: .env
    ports:
      - "8080:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    links:
      - "postgres:pgsql-server"
    networks:
      - djangonetwork

  redis:
    restart: always
    env_file: .env
    image: redis:6.0.9-alpine
    expose:
      - "6379"
  celery:
    restart: always
    env_file: .env
    build: .
    command: celery -A core worker -l info
    volumes:
      - .:/Finance_Django_Project
    depends_on:
      - web
      - redis
  celery-beat:
    restart: always
    env_file: .env
    build: .
    command: celery -A core beat -l info
    volumes:
      - .:/Finance_Django_Project
    depends_on:
      - web
      - redis


networks: 
  djangonetwork:
    driver: bridge

volumes:
  finance_django_project_data:
  postgres_data:
  pgadmin_data: